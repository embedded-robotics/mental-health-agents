{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning LLaMA-3.2 3B Instruct\n",
    "\n",
    "This code will fine-tune the `LLaMA-3.2-3B-Instruct` model on the CounselChat dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/mn27889/miniconda3/envs/mental-health-agents/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported, train_on_responses_only\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq, TextStreamer\n",
    "from datasets import Dataset, DatasetDict\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some links to be used for fine-tuning\n",
    "1. https://www.kdnuggets.com/fine-tuning-llama-using-unsloth\n",
    "2. https://www.analyticsvidhya.com/blog/2024/12/fine-tuning-llama-3-2-3b-for-rag/\n",
    "3. https://www.linkedin.com/pulse/step-guide-use-fine-tune-llama-32-dr-oualid-soula-xmnff/\n",
    "4. https://medium.com/@alexandros_chariton/how-to-fine-tune-llama-3-2-instruct-on-your-own-data-a-detailed-guide-e5f522f397d7 (this seems faulty since it copies the output id's within the input_ids)\n",
    "5. https://drlee.io/step-by-step-guide-fine-tuning-metas-llama-3-2-1b-model-f1262eda36c8\n",
    "6. https://huggingface.co/blog/ImranzamanML/fine-tuning-1b-llama-32-a-comprehensive-article\n",
    "7. https://blog.futuresmart.ai/fine-tune-llama-32-vision-language-model-on-custom-datasets\n",
    "8. https://github.com/meta-llama/llama-cookbook/blob/main/getting-started/finetuning/multigpu_finetuning.md\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Counsel Chat Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>question</th>\n",
       "      <th>answerText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relationships</td>\n",
       "      <td>I am currently suffering from erectile dysfunc...</td>\n",
       "      <td>Hi, First and foremost, I want to acknowledge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>family-conflict</td>\n",
       "      <td>For the past week or so me and my boyfriend ha...</td>\n",
       "      <td>Forgetting one's emotions is impossible.Since ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>depression</td>\n",
       "      <td>I am in high school and have been facing anxie...</td>\n",
       "      <td>Hi Helena,I felt a bit sad when I read this. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>I'm concerned about my boyfriend. I suffer fro...</td>\n",
       "      <td>Hello! Thank you for your question. There are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spirituality</td>\n",
       "      <td>I'm a Christian teenage girl, and I have lost ...</td>\n",
       "      <td>Having sex with your boyfriend is and was a mi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             topic                                           question  \\\n",
       "0    relationships  I am currently suffering from erectile dysfunc...   \n",
       "1  family-conflict  For the past week or so me and my boyfriend ha...   \n",
       "2       depression  I am in high school and have been facing anxie...   \n",
       "3          anxiety  I'm concerned about my boyfriend. I suffer fro...   \n",
       "4     spirituality  I'm a Christian teenage girl, and I have lost ...   \n",
       "\n",
       "                                          answerText  \n",
       "0  Hi, First and foremost, I want to acknowledge ...  \n",
       "1  Forgetting one's emotions is impossible.Since ...  \n",
       "2  Hi Helena,I felt a bit sad when I read this. T...  \n",
       "3  Hello! Thank you for your question. There are ...  \n",
       "4  Having sex with your boyfriend is and was a mi...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('processed_data/counselchat_top_votes_train.pkl', 'rb') as file:\n",
    "    dataset_top_votes_train = pickle.load(file)\n",
    "\n",
    "dataset_top_votes_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>question</th>\n",
       "      <th>answerText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relationships</td>\n",
       "      <td>I had to go to the emergency room today to get...</td>\n",
       "      <td>It is extremely frustrating when our significa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>marriage</td>\n",
       "      <td>What makes a healthy marriage last? What makes...</td>\n",
       "      <td>This is a fantastic question. In one sentence,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relationships</td>\n",
       "      <td>I'm a female freshman in high school, and this...</td>\n",
       "      <td>First off, I think it is great that you are wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intimacy</td>\n",
       "      <td>My wife and I are newly married, about 2 month...</td>\n",
       "      <td>You are newly married, you Have a hectic sched...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>legal-regulatory</td>\n",
       "      <td>I think I have depression, anxiety, bipolar di...</td>\n",
       "      <td>It can be difficult to get counseling if you d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              topic                                           question  \\\n",
       "0     relationships  I had to go to the emergency room today to get...   \n",
       "1          marriage  What makes a healthy marriage last? What makes...   \n",
       "2     relationships  I'm a female freshman in high school, and this...   \n",
       "3          intimacy  My wife and I are newly married, about 2 month...   \n",
       "4  legal-regulatory  I think I have depression, anxiety, bipolar di...   \n",
       "\n",
       "                                          answerText  \n",
       "0  It is extremely frustrating when our significa...  \n",
       "1  This is a fantastic question. In one sentence,...  \n",
       "2  First off, I think it is great that you are wi...  \n",
       "3  You are newly married, you Have a hectic sched...  \n",
       "4  It can be difficult to get counseling if you d...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('processed_data/counselchat_top_votes_test.pkl', 'rb') as file:\n",
    "    dataset_top_votes_test = pickle.load(file)\n",
    "\n",
    "dataset_top_votes_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the HuggingFace dataset using Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Dataset.from_pandas(dataset_top_votes_train)\n",
    "dataset_test = Dataset.from_pandas(dataset_top_votes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict()\n",
    "dataset['train'] = dataset_train\n",
    "dataset['test'] = dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['topic', 'question', 'answerText'],\n",
       "        num_rows: 690\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['topic', 'question', 'answerText'],\n",
       "        num_rows: 173\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.2.\n",
      "   \\\\   /|    NVIDIA RTX A6000. Num GPUs = 1. Max memory: 47.413 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.4.1+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.0.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post1. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 2048 \n",
    "dtype = None # None for auto-detection.\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-1B-Instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    dtype=dtype,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the PEFT settings for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.3.19 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\", \n",
    "    random_state = 42,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forming the chat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply the chat template\n",
    "def format_chat_template(example):\n",
    "        \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert mental health professional trained to counsel and guide patients suffering from ill mental-health\"},\n",
    "        {\"role\": \"user\", \"content\": example['question']},\n",
    "        {\"role\": \"assistant\", \"content\": example['answerText']}\n",
    "    ]\n",
    "    \n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "    return {\"text\": prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [00:00<00:00, 6505.28 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 173/173 [00:00<00:00, 4582.90 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_formatted = dataset.map(format_chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 28 Mar 2025\n",
      "\n",
      "You are an expert mental health professional trained to counsel and guide patients suffering from ill mental-health<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "I am currently suffering from erectile dysfunction and have tried Viagra, Cialis, etc. Nothing seemed to work. My girlfriend of 3 years is very sexually frustrated. I told her that it is okay for her to have sex with other men. Is that really okay? Is it okay for my girlfriend to have sex with other men since I can't sexually perform?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Hi, First and foremost, I want to acknowledge your efforts to gain (your) ideal erectile function. If the medications are not working and you have taken them as prescribed, I would encourage you to seek the help of a sex therapist as the dysfunction may be due to a psychological and/or relational issue rather than a physical/medical one. As for your question, only you can answer this. Is it OK? Are you OK with her sleeping with others? Have you thought through what this may look like, feel like, become for you and her? Opening up a relationship is a choice only the people in the relationship can answer. Even then, the answer may change at any point by either of you. I encourage you to also determine what the intention is underneath your telling your girlfriend she could sleep with others. Be clear with the intention and then together have continuous conversations about the expectations of opening up (i.e.: are there any kinds of sex that is off limits, areas of the body where touch or intimacy is not allowed, are uses of safer sex required or not, do you want to know the details or not, so forth). An excellent resource would be the book \"Opening Up\" by Tristan Taormino. I wish you the best of luck!Dr. Lily Zehner, MFT-C<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(dataset_formatted['train']['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing the TRL SFTTrainer and related Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"text\"] (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [00:02<00:00, 302.78 examples/s]\n",
      "Unsloth: Tokenizing [\"text\"] (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 173/173 [00:01<00:00, 101.05 examples/s]\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "new_model = \"./llama32-sft-fine-tune-counselchat\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        output_dir=new_model,\n",
    "        per_device_train_batch_size=2,\n",
    "        per_device_eval_batch_size=2,\n",
    "        # gradient_accumulation_steps=4,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=0.1,\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=50,\n",
    "        save_strategy=\"epoch\",\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 3,\n",
    "        learning_rate = 1e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 42,\n",
    "        report_to = \"none\",\n",
    "    )\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset=dataset_formatted[\"train\"],\n",
    "    eval_dataset=dataset_formatted[\"test\"],\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer), #only use when using train_on_responses_only()\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['topic', 'question', 'answerText', 'text', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 690\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 28 Mar 2025\n",
      "\n",
      "You are an expert mental health professional trained to counsel and guide patients suffering from ill mental-health<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "I am currently suffering from erectile dysfunction and have tried Viagra, Cialis, etc. Nothing seemed to work. My girlfriend of 3 years is very sexually frustrated. I told her that it is okay for her to have sex with other men. Is that really okay? Is it okay for my girlfriend to have sex with other men since I can't sexually perform?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Hi, First and foremost, I want to acknowledge your efforts to gain (your) ideal erectile function. If the medications are not working and you have taken them as prescribed, I would encourage you to seek the help of a sex therapist as the dysfunction may be due to a psychological and/or relational issue rather than a physical/medical one. As for your question, only you can answer this. Is it OK? Are you OK with her sleeping with others? Have you thought through what this may look like, feel like, become for you and her? Opening up a relationship is a choice only the people in the relationship can answer. Even then, the answer may change at any point by either of you. I encourage you to also determine what the intention is underneath your telling your girlfriend she could sleep with others. Be clear with the intention and then together have continuous conversations about the expectations of opening up (i.e.: are there any kinds of sex that is off limits, areas of the body where touch or intimacy is not allowed, are uses of safer sex required or not, do you want to know the details or not, so forth). An excellent resource would be the book \"Opening Up\" by Tristan Taormino. I wish you the best of luck!Dr. Lily Zehner, MFT-C<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(trainer.train_dataset['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only Focus on the `Response Part` for the generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=64): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [00:01<00:00, 387.61 examples/s]\n",
      "Map (num_proc=64): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 173/173 [00:01<00:00, 110.63 examples/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
    "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['topic', 'question', 'answerText', 'text', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 690\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " 13347,\n",
       " 11,\n",
       " 5629,\n",
       " 323,\n",
       " 43780,\n",
       " 11,\n",
       " 358,\n",
       " 1390,\n",
       " 311,\n",
       " 25670,\n",
       " 701,\n",
       " 9045,\n",
       " 311,\n",
       " 8895,\n",
       " 320,\n",
       " 22479,\n",
       " 8,\n",
       " 10728,\n",
       " 57217,\n",
       " 734,\n",
       " 13,\n",
       " 1442,\n",
       " 279,\n",
       " 31010,\n",
       " 527,\n",
       " 539,\n",
       " 3318,\n",
       " 323,\n",
       " 499,\n",
       " 617,\n",
       " 4529,\n",
       " 1124,\n",
       " 439,\n",
       " 32031,\n",
       " 11,\n",
       " 358,\n",
       " 1053,\n",
       " 15253,\n",
       " 499,\n",
       " 311,\n",
       " 6056,\n",
       " 279,\n",
       " 1520,\n",
       " 315,\n",
       " 264,\n",
       " 1877,\n",
       " 42863,\n",
       " 439,\n",
       " 279,\n",
       " 32403,\n",
       " 1253,\n",
       " 387,\n",
       " 4245,\n",
       " 311,\n",
       " 264,\n",
       " 24064,\n",
       " 323,\n",
       " 5255,\n",
       " 72283,\n",
       " 4360,\n",
       " 4856,\n",
       " 1109,\n",
       " 264,\n",
       " 7106,\n",
       " 14,\n",
       " 69216,\n",
       " 832,\n",
       " 13,\n",
       " 1666,\n",
       " 369,\n",
       " 701,\n",
       " 3488,\n",
       " 11,\n",
       " 1193,\n",
       " 499,\n",
       " 649,\n",
       " 4320,\n",
       " 420,\n",
       " 13,\n",
       " 2209,\n",
       " 433,\n",
       " 10619,\n",
       " 30,\n",
       " 8886,\n",
       " 499,\n",
       " 10619,\n",
       " 449,\n",
       " 1077,\n",
       " 21811,\n",
       " 449,\n",
       " 3885,\n",
       " 30,\n",
       " 12522,\n",
       " 499,\n",
       " 3463,\n",
       " 1555,\n",
       " 1148,\n",
       " 420,\n",
       " 1253,\n",
       " 1427,\n",
       " 1093,\n",
       " 11,\n",
       " 2733,\n",
       " 1093,\n",
       " 11,\n",
       " 3719,\n",
       " 369,\n",
       " 499,\n",
       " 323,\n",
       " 1077,\n",
       " 30,\n",
       " 41137,\n",
       " 709,\n",
       " 264,\n",
       " 5133,\n",
       " 374,\n",
       " 264,\n",
       " 5873,\n",
       " 1193,\n",
       " 279,\n",
       " 1274,\n",
       " 304,\n",
       " 279,\n",
       " 5133,\n",
       " 649,\n",
       " 4320,\n",
       " 13,\n",
       " 7570,\n",
       " 1243,\n",
       " 11,\n",
       " 279,\n",
       " 4320,\n",
       " 1253,\n",
       " 2349,\n",
       " 520,\n",
       " 904,\n",
       " 1486,\n",
       " 555,\n",
       " 3060,\n",
       " 315,\n",
       " 499,\n",
       " 13,\n",
       " 358,\n",
       " 15253,\n",
       " 499,\n",
       " 311,\n",
       " 1101,\n",
       " 8417,\n",
       " 1148,\n",
       " 279,\n",
       " 14944,\n",
       " 374,\n",
       " 30456,\n",
       " 701,\n",
       " 11890,\n",
       " 701,\n",
       " 23601,\n",
       " 1364,\n",
       " 1436,\n",
       " 6212,\n",
       " 449,\n",
       " 3885,\n",
       " 13,\n",
       " 2893,\n",
       " 2867,\n",
       " 449,\n",
       " 279,\n",
       " 14944,\n",
       " 323,\n",
       " 1243,\n",
       " 3871,\n",
       " 617,\n",
       " 19815,\n",
       " 21633,\n",
       " 922,\n",
       " 279,\n",
       " 17078,\n",
       " 315,\n",
       " 8736,\n",
       " 709,\n",
       " 320,\n",
       " 72,\n",
       " 1770,\n",
       " 18976,\n",
       " 527,\n",
       " 1070,\n",
       " 904,\n",
       " 13124,\n",
       " 315,\n",
       " 1877,\n",
       " 430,\n",
       " 374,\n",
       " 1022,\n",
       " 13693,\n",
       " 11,\n",
       " 5789,\n",
       " 315,\n",
       " 279,\n",
       " 2547,\n",
       " 1405,\n",
       " 5916,\n",
       " 477,\n",
       " 66264,\n",
       " 374,\n",
       " 539,\n",
       " 5535,\n",
       " 11,\n",
       " 527,\n",
       " 5829,\n",
       " 315,\n",
       " 30549,\n",
       " 1877,\n",
       " 2631,\n",
       " 477,\n",
       " 539,\n",
       " 11,\n",
       " 656,\n",
       " 499,\n",
       " 1390,\n",
       " 311,\n",
       " 1440,\n",
       " 279,\n",
       " 3649,\n",
       " 477,\n",
       " 539,\n",
       " 11,\n",
       " 779,\n",
       " 13544,\n",
       " 570,\n",
       " 1556,\n",
       " 9250,\n",
       " 5211,\n",
       " 1053,\n",
       " 387,\n",
       " 279,\n",
       " 2363,\n",
       " 330,\n",
       " 52398,\n",
       " 3216,\n",
       " 1,\n",
       " 555,\n",
       " 97690,\n",
       " 24172,\n",
       " 494,\n",
       " 3394,\n",
       " 13,\n",
       " 358,\n",
       " 6562,\n",
       " 499,\n",
       " 279,\n",
       " 1888,\n",
       " 315,\n",
       " 15369,\n",
       " 0,\n",
       " 9023,\n",
       " 13,\n",
       " 48390,\n",
       " 1901,\n",
       " 2701,\n",
       " 1215,\n",
       " 11,\n",
       " 386,\n",
       " 4082,\n",
       " 7813,\n",
       " 128009]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The labels are created which only contain response. Left Padding is implemented and all the padding tokens are given a score of -100 to avoid loss calculation for pad_tokens\n",
    "trainer.train_dataset['labels'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 690 | Num Epochs = 3 | Total steps = 1,035\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 1 x 1) = 2\n",
      " \"-____-\"     Trainable parameters = 11,272,192/1,000,000,000 (1.13% trained)\n",
      "/usr/bin/ld: skipping incompatible /usr/lib/i386-linux-gnu/libcuda.so when searching for -lcuda\n",
      "/usr/bin/ld: skipping incompatible /usr/lib/i386-linux-gnu/libcuda.so when searching for -lcuda\n",
      "/usr/bin/ld: skipping incompatible /usr/lib/i386-linux-gnu/libcuda.so when searching for -lcuda\n",
      "/usr/bin/ld: skipping incompatible /usr/lib/i386-linux-gnu/libcuda.so when searching for -lcuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1035' max='1035' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1035/1035 04:49, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>2.771700</td>\n",
       "      <td>2.750295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>2.738200</td>\n",
       "      <td>2.728503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>312</td>\n",
       "      <td>2.715700</td>\n",
       "      <td>2.709515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>2.594100</td>\n",
       "      <td>2.707229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.601600</td>\n",
       "      <td>2.705599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>624</td>\n",
       "      <td>2.573000</td>\n",
       "      <td>2.698253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>728</td>\n",
       "      <td>2.511500</td>\n",
       "      <td>2.710515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>832</td>\n",
       "      <td>2.399200</td>\n",
       "      <td>2.727563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>936</td>\n",
       "      <td>2.355200</td>\n",
       "      <td>2.729983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./llama32-sft-fine-tune-counselchat/tokenizer_config.json',\n",
       " './llama32-sft-fine-tune-counselchat/special_tokens_map.json',\n",
       " './llama32-sft-fine-tune-counselchat/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(new_model)\n",
    "tokenizer.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = \"./llama32-sft-fine-tune-counselchat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.2.\n",
      "   \\\\   /|    NVIDIA RTX A6000. Num GPUs = 1. Max memory: 47.413 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.4.1+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.0.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post1. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.3.19 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 2048 \n",
    "dtype = None # None for auto-detection.\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = new_model,\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    dtype=dtype,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I am currently suffering from erectile dysfunction and have tried Viagra, Cialis, etc. Nothing seemed to work. My girlfriend of 3 years is very sexually frustrated. I told her that it is okay for her to have sex with other men. Is that really okay? Is it okay for my girlfriend to have sex with other men since I can't sexually perform?\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['question'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "It sounds like you are both at a loss for how to handle this situation. It is understandable that you are having trouble with your sexual performance. It is also understandable that you are concerned about your girlfriend's sexual well-being. You may want to consider talking with your girlfriend about what she is feeling and what she is thinking. It may be helpful for her to talk with a counselor or therapist. I would encourage you to seek counseling as well. The two of you may be able to get through this together.\n"
     ]
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are an expert mental health professional trained to counsel and guide patients suffering from ill mental-health\"},\n",
    "    {\"role\": \"user\", \"content\": dataset['train']['question'][0]}]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    \n",
    "inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=2048, num_return_sequences=1)\n",
    "\n",
    "text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(text.split(\"assistant\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mental-health-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
